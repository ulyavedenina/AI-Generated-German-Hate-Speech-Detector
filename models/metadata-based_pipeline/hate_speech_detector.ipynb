{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hda12228/botox/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "2024-09-05 08:35:09.851118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-05 08:35:09.866122: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-05 08:35:09.866147: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-05 08:35:09.877512: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-05 08:35:10.636446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer, setup_chat_format\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import re\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: 1\n",
      "Available GPUs after setting CUDA_VISIBLE_DEVICES: 1\n",
      "Using device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "# Count GPUs\n",
    "print(\"Available GPUs:\", torch.cuda.device_count())\n",
    "\n",
    "# Set CUDA_VISIBLE_DEVICES to use only GPU 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Count GPUs again to see if the change took effect\n",
    "print(\"Available GPUs after setting CUDA_VISIBLE_DEVICES:\", torch.cuda.device_count())\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device(\"cuda:1\") \n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb9529aa444426189f384e95a5e4555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472d6b595f4b48b9adf0da5239aa95ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b9892082584c2b8b23a52c6991cd17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1997 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': '\\nDefiniere, ob der Kommentar Hassrede enthält\\n0 - Keine Hassrede\\n1 - Enthält Hassrede\\n', 'role': 'system'}, {'content': 'ja wer heute noch grün wählt, kann auch gleich abdampfen, rene benko freund scholz wird kanzler, lang ohne abschluss wird ministerin, bearbock hat im lebenslauf gelogen mit ihren 2 jahren studium in england. da spricht nen 3 jähriger besseres englisch. und was wird sie, natürlich aussenminister. betrug lüge und wirtschaften in die eigene tasche. egal welche partei, dass sind alles verbrecher und nur solche werden sich immer wieder durchsetzen. solange man nicht anfängt, lügenpolitik und lobbyisten-polotik unter strafe zu stellen. das land geht bergab, aber unsere regierung hält es für wichtiger, auslandsprojekte im 3 stelligen millionenbereich zu unterstützen aber hier bekommt der rentner nach 45 jahre aufn bau, nen verfickten arschtritt als rente und den arschtritt gibts monatlich, aber sich selber wieder die diäten erhöhen, diese korrupte drecksregierung', 'role': 'user'}, {'content': '1.0', 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "\n",
    "data = pd.read_csv('training_set_hate_speech.tsv',  delimiter='\\t')\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_target_val = pd.read_csv('final_test_set.tsv',  sep='\\t')\n",
    "\n",
    "system_message = \"\"\"\n",
    "Definiere, ob der Kommentar Hassrede enthält\n",
    "0 - Keine Hassrede\n",
    "1 - Enthält Hassrede\n",
    "\"\"\"\n",
    "\n",
    "dataset_tr, dataset_val = train_test_split(data, test_size=0.2, stratify=data['label'], random_state=seed)\n",
    "\n",
    "def convert_dataset(data):\n",
    "    prompt= [{\"role\": \"system\", \"content\": system_message}, \n",
    "             {\"role\": \"user\", \"content\": str(data[\"text\"])},\n",
    "             {\"role\": \"assistant\", \"content\": str(data[\"label\"])}]\n",
    "    return {'messages': prompt}\n",
    "\n",
    "dataset_tr = Dataset.from_pandas(dataset_val)\n",
    "dataset_val = Dataset.from_pandas(dataset_val)\n",
    "dataset_target_val = Dataset.from_pandas(data_target_val)\n",
    "\n",
    "dataset_tr = dataset_tr.map(convert_dataset, remove_columns=dataset_tr.features)\n",
    "dataset_val = dataset_val.map(convert_dataset, remove_columns=dataset_val.features)\n",
    "dataset_target_val = dataset_target_val.map(convert_dataset, remove_columns=dataset_target_val.features)\n",
    "\n",
    "print(dataset_target_val[1][\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/media/data/uv/Meta-Llama-3-8B-Instruct'\n",
    "FT_PATH = \"/media/data/uv/llama-8b-hate-ft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_tokenizer = AutoTokenizer.from_pretrained(PATH, trust_remote_code=True)\n",
    "llama_tokenizer.padding_side = \"right\"\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    #load_in_8bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    PATH,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "base_model.config.pretraining_tp = 1\n",
    "\n",
    "model, tokenizer = setup_chat_format(base_model, llama_tokenizer)\n",
    "\n",
    "peft_parameters = LoraConfig(\n",
    "    lora_alpha=256,\n",
    "    lora_dropout=0.1,\n",
    "    r=256,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    "\n",
    ")\n",
    "\n",
    "train_params = TrainingArguments(\n",
    "    output_dir=\"/media/data/uv/llama-8b-hate-ft/results\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim='paged_adamw_32bit',\n",
    "    save_steps=100,\n",
    "    logging_steps=100,\n",
    "    learning_rate=2e-3,\n",
    "    weight_decay=1e-4,\n",
    "    max_grad_norm=1.0,\n",
    "    warmup_ratio=0.0,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type='linear',\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "ft = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset_tr,\n",
    "    peft_config=peft_parameters,\n",
    "    tokenizer=tokenizer,\n",
    "    args=train_params,\n",
    "    max_seq_length=512,\n",
    ")\n",
    "\n",
    "ft.train()\n",
    "ft.model.save_pretrained(FT_PATH)\n",
    "tokenizer.save_pretrained(FT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "logging.set_verbosity(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, tokenizer, llama_tokenizer, ft, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model_path = \"/media/data/uv/llama-8b-hate-merged\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(PATH, low_cpu_mem_usage=True, return_dict=True, torch_dtype=torch.float16, device_map={\"\": 0})\n",
    "model = PeftModel.from_pretrained(base_model, FT_PATH)\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(merged_model_path)\n",
    "print('The merged model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de73d32ba7784ebf9d76ba72d5cf3f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The merged model uploaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokenizer uploaded\n",
      "The pipeline initialized\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model = AutoModelForCausalLM.from_pretrained(merged_model_path)\n",
    "print('The merged model uploaded')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(PATH, trust_remote_code=True)\n",
    "print('The tokenizer uploaded')\n",
    "\n",
    "text_generator = pipeline(\"text-generation\", model=fine_tuned_model, tokenizer=tokenizer)\n",
    "print('The pipeline initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 0 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 1 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 2 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 3 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 4 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 5 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 6 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 7 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 8 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 9 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 10 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 11 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 12 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 13 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 14 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 15 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 16 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 17 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 18 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 19 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 20 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 21 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 22 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 23 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 24 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 25 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 26 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 27 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 28 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 29 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 30 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 31 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 32 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 33 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 34 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 35 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 36 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 37 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 38 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 39 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 40 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 41 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 42 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 43 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 44 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 45 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 46 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 47 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 48 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 49 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 50 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 51 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 52 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 53 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 54 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 55 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 56 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 57 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 58 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 59 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 60 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 61 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 62 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 63 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 64 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 65 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 66 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 67 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 68 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 69 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 70 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 71 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 72 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 73 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 74 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 75 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 76 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 77 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 78 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 79 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 80 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 81 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 82 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 83 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 84 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 85 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 86 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 87 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 88 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 89 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 90 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 91 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 92 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 93 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 94 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 95 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 96 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 97 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 98 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 99 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 100 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 101 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 102 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 103 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 104 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 105 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 106 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 107 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 108 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 109 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 110 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 111 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 112 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 113 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 114 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 115 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 116 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 117 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 118 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 119 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 120 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 121 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 122 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 123 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 124 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 125 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 126 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 127 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 128 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 129 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 130 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 131 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 132 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 133 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 134 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 135 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 136 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 137 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 138 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 139 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 140 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 141 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 142 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 143 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 144 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 145 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 146 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 147 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 148 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 149 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 150 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 151 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 152 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 153 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 154 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 155 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 156 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 157 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 158 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 159 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 160 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 161 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 162 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 163 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 164 generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt for index 165 generated\n"
     ]
    }
   ],
   "source": [
    "generated_texts = []\n",
    "\n",
    "for idx, data in enumerate(dataset_val):\n",
    "    prompt = tokenizer.apply_chat_template(data[\"messages\"][:2], tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    outputs = text_generator(\n",
    "        prompt,\n",
    "        max_new_tokens=1,\n",
    "        do_sample=True,\n",
    "        temperature=0.1,\n",
    "        top_k=10,\n",
    "        top_p=0.1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    print(f'The prompt for index {idx} generated')\n",
    "    generated_texts.append(outputs[0]['generated_text'])\n",
    "print('The test texts generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = data_target_val['label'].tolist()\n",
    "\n",
    "predicted_labels = [int(text.split()[-1]) if text.split()[-1].isdigit() else -1 for text in generated_texts]\n",
    "\n",
    "output= {'comment' : data_target_val['text'],\n",
    "         'label' : data_target_val['label'].astype(int), \n",
    "         'pred' : predicted_labels,\n",
    "                     }\n",
    "    \n",
    "output = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"([^/]+$)\"\n",
    "match = re.search(pattern, PATH)\n",
    "output.to_csv(f'predictions_{match.group(1)}_1.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('predictions_Meta-Llama-3-8B-Instruct.tsv', sep='\\t')\n",
    "\n",
    "true_labels = df.label\n",
    "predicted_labels = df.pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7320981472208312\n",
      "F1-score: 0.7635341724025233\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "f_score = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "print(\"F1-score:\", f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "botox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
