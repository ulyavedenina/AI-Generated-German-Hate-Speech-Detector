{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b45ebc3c-87ce-4dec-801d-577ae335e14f",
   "metadata": {},
   "source": [
    "# BERT Embeddings + Stylometric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb7ba2-b1ee-4fd9-b603-15239331446b",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "892aa163-04ec-42e3-8252-be3d410d7ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from ignite.handlers import EarlyStopping\n",
    "import random\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import NuSVC\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import peft\n",
    "from peft import PeftConfig, PeftModel\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658e4165-4db7-40b3-a0eb-d5db5a341371",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eda393ba-c078-4463-8c7a-c7f28c37b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "#torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41260c8b-1aab-42f4-9079-9713f12f59c6",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d2a10d6-f741-44a0-ba22-89af1558396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../../../dataset/text-based/train.tsv', sep='\\t', encoding='utf-8', engine='python')\n",
    "# rearrange column order\n",
    "col_name = 'text_light_clean'\n",
    "X_train[col_name] = X_train.pop(col_name)\n",
    "X_test =  pd.read_csv('../../../dataset/text-based/test.tsv', sep='\\t', encoding='utf-8', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19027578-42e5-4083-8b47-97eff8a5d33a",
   "metadata": {},
   "source": [
    "## Prepare Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ca5cb439-9eaf-49a5-90bb-2c1d7056620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "y_train = X_train['label']\n",
    "y_test = X_test['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76a6bf9-bbb5-48ff-b01a-5aba5898e8d6",
   "metadata": {},
   "source": [
    "## BERT Embeddings with mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b87d5dc-7dba-4a9e-8cfb-0c5864573353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT model\n",
    "# with pooling \n",
    "word_embedding_model = models.Transformer(\"dbmdz/bert-base-german-uncased\", max_seq_length=256)   #>256 not recommended: https://stackoverflow.com/questions/75901231/max-seq-length-for-transformer-sentence-bert\n",
    "pooling_model = models.Pooling(word_embedding_dimension = word_embedding_model.get_word_embedding_dimension(), pooling_mode='mean')\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a2911-e67c-4a9c-aea1-c5fb8a358af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sentences\n",
    "X_train_embeddings = model.encode(X_train['text_light_clean'].values, show_progress_bar=True)\n",
    "X_test_embeddings = model.encode(X_test['text_light_clean'].values, show_progress_bar= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78dff2a-288c-4450-ae72-c8ab8bb92817",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape Train: {X_train_embeddings.shape}')\n",
    "print('##################')\n",
    "print(f'Shape Test: {X_test_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256545ef-7d28-4ff4-95a5-640a692afe4f",
   "metadata": {},
   "source": [
    "## Adding the stylometric features to mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad0bd3-0c1d-4ede-bd11-4f4d31f9cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stylo = X_train.drop(['index', 'text', 'label', 'text_light_clean'], axis=1)\n",
    "X_train_stylo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3863201f-0e99-4bd1-98cc-77f600b136c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_stylo = X_test.drop(['index','text','label', 'text_light_clean'], axis=1)\n",
    "X_test_stylo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf5c600c-496a-4ac4-a566-597193456af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stylo = X_train_stylo.to_numpy()\n",
    "X_test_stylo = X_test_stylo.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587bcbc1-655b-49de-a965-0b347ed3d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ges_train = np.hstack([X_train_embeddings, X_train_stylo])\n",
    "X_train = X_ges_train\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e65a25-9d13-4222-8070-56ea6579f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ges_test = np.hstack([X_test_embeddings, X_test_stylo])\n",
    "X_test = X_ges_test\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d981c655-da8c-4abd-82a7-d30d9bb740a2",
   "metadata": {},
   "source": [
    "### Normalise the input data points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d96cd24-313a-42d3-895f-1ede390743d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = min_max_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cda57500-0c15-46e6-b490-cbf2840a06d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9806669c-1909-4554-a4e3-162a011faef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = min_max_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0c4ef67c-5823-4f0c-9001-d0257e708e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ca346a-c151-47ae-bcab-0cb96e2e21c5",
   "metadata": {},
   "source": [
    "### Data for MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4fd8d893-6c7d-49c6-8049-036a51bbae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test-Split \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b349e-4727-4986-b689-f5bf84cb3cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fc9ebd-1e72-4e9a-84fe-b4cf1b7ddf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21a935c5-6964-48b7-99bb-1c2cf463e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "X_val_tensor = torch.from_numpy(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "54f98794-9cd0-4d9d-9773-e3402b442a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = X_train_tensor.float()\n",
    "X_val_tensor = X_val_tensor.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b4428857-4173-4122-84f4-b3570537bdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "y_val_tensor = torch.from_numpy(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f51daac5-7b22-4117-8c09-93d42dce872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4ee92895-1ab3-47cf-84be-922bf1d0aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Reproducibility - Dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c54fc252-74af-4f62-8266-27fdbd8e0454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b509550-fa5e-450c-8009-f592555d5d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eb6c8dfa-3ec3-4063-b5cf-872006c47b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g,\n",
    ")\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_val_tensor, y_val_tensor),\n",
    "    batch_size=batch_size,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17488a31-9681-4383-8d83-793d8356be46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testdata \n",
    "X_test_tensor = torch.from_numpy(X_test_scaled)\n",
    "X_test_tensor = X_test_tensor.float()\n",
    "y_test_tensor = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "538833c3-1872-4ab6-8cfa-8086a4a8f305",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor),\n",
    "    batch_size=batch_size,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53177fc0-4772-49e8-95ff-1691c76aacd8",
   "metadata": {},
   "source": [
    "### Simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ddb3349a-267d-4706-ba27-7a42c39013e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=821, num_units_hidden=824, dropout_prob=0.5): # num_units_hidden = n+m+2 = 824\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(input_size, num_units_hidden),\n",
    "            nn.ReLU(),  \n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(num_units_hidden, 2),\n",
    "            nn.LogSoftmax(dim=-1),\n",
    "        )\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.seq(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0695ec2-d156-4bfb-9374-4da6d143859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping from https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch/71999355#71999355 \n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f9b4a-dc81-492c-94bf-f018125d5217",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f036a6a8-4453-4242-a6f3-dfab3c364749",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001 \n",
    "batch_size = 64\n",
    "max_epochs = 200\n",
    "weight_decay = 0.1\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda\"\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "33f303e5-123f-485b-a5a4-d5e7d90e2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_dataloader, eval_dataloader, epochs, patience=10, save_path='./best-model-parameters.pt'): # change Path\n",
    "    early_stopper = EarlyStopper(patience=patience, min_delta=0) \n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for xb, yb in train_dataloader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            outputs = model(xb)\n",
    "            loss = criterion(outputs, yb)\n",
    "            train_loss += loss.detach().item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for xb, yb in eval_dataloader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(xb)\n",
    "                loss = criterion(outputs, yb)\n",
    "                eval_loss += loss.detach().item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                y_true.extend(yb.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        eval_loss_total = eval_loss / len(eval_dataloader)\n",
    "        train_loss_total = train_loss / len(train_dataloader)\n",
    "        \n",
    "        train_losses.append(train_loss_total)  \n",
    "        eval_losses.append(eval_loss_total)            \n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1}/{epochs}, Train Loss: {train_loss_total:.4f}, Eval Loss: {eval_loss_total:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if early_stopper.early_stop(eval_loss_total):\n",
    "            print(f\"No improvement for {patience} epochs. Early stopping...\")\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'Model saved to {save_path}')\n",
    "            break\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f'Model saved to {save_path}')\n",
    "    # Plotting\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(eval_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4050bf33-7ed7-41a5-970a-d05a138ba992",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = MLP().to(device)\n",
    "optimizer = torch.optim.AdamW(module.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "criterion = nn.NLLLoss() #because of Logsoftmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad68d26-367b-4130-be45-18c94f24e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time train(module, optimizer, criterion, train_dataloader, eval_dataloader, epochs=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d3717-e779-417b-8dd3-2686fdec57a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on testdata  \n",
    "best_model = MLP()\n",
    "best_model.load_state_dict(torch.load('./best-model-parameters.pt', map_location=torch.device('cpu'))) # change Path\n",
    "best_model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "y_true_test = []\n",
    "y_pred_test = []\n",
    "for xb, yb in test_dataloader:\n",
    "    with torch.no_grad():\n",
    "        outputs = best_model(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        test_loss += loss.detach().item()\n",
    "\n",
    "        # Calculate predictions\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true_test.extend(yb.numpy())\n",
    "        y_pred_test.extend(predicted.numpy())\n",
    "\n",
    "test_loss_total = test_loss / len(test_dataloader)\n",
    "f1_test = f1_score(y_true_test, y_pred_test)\n",
    "print(f\"Test Loss: {test_loss_total:.4f}, F1 Score (Test): {f1_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "69c10f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"y_label\":y_true_test, \"y_pred\":y_pred_test}).to_csv(\"results.tsv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
