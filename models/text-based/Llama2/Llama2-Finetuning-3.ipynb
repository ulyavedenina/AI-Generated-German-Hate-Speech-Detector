{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11614054",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "To successfully run the following notebook, in the output of the first cell you need to insert a valid Llama2 access token. This token can be requested on their model card (https://huggingface.co/meta-llama/Llama-2-13b-hf).\n",
    "\n",
    "A GPU is highly recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212a36f8-af3b-4833-ab00-4290068dc274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BitsAndBytesConfig, TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model, TaskType\n",
    "import bitsandbytes as bnb\n",
    "import datasets\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c53543-ba44-47e8-bb89-f9c3d7d29661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count GPUs\n",
    "print(torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d150ca5-5cc9-4a96-8141-7b09889d4ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count GPUs\n",
    "print(\"Available GPUs:\", torch.cuda.device_count())\n",
    "\n",
    "# Set CUDA_VISIBLE_DEVICES to use only GPU 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Count GPUs again to see if the change took effect\n",
    "print(\"Available GPUs after setting CUDA_VISIBLE_DEVICES:\", torch.cuda.device_count())\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device(\"cuda:1\") \n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbd37f-b4e8-4331-a1c1-7018bb70f3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change model_id to either 7b or 13b\n",
    "model_id = \"meta-llama/Llama-2-13b-hf\" # \"meta-llama/Llama-2-7b-hf\" \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbb5168d-fc3b-46e2-9034-7049b39ecb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_train = datasets.load_from_disk(\"../../../dataset/datasets_llama/bot_ds\")[\"train\"] # change \n",
    "no_bot_train = datasets.load_from_disk(\"../../../dataset/datasets_llama/no_bot_ds\")[\"train\"] # change \n",
    "bot_train = bot_train.add_column(\"output\", [1]*len(bot_train))  \n",
    "no_bot_train = no_bot_train.add_column(\"output\", [0]*len(no_bot_train))\n",
    "train_dataset = datasets.concatenate_datasets([bot_train, no_bot_train])\n",
    "train_dataset = train_dataset.shuffle(10)\n",
    "train_sentences, train_labels = train_dataset['text'], train_dataset['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2dcf8dc-50c2-4295-92f9-5d7e10f4ebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_val = datasets.load_from_disk(\"../../../dataset/datasets_llama/bot_ds\")[\"val\"] # change \n",
    "no_bot_val = datasets.load_from_disk(\"../../../dataset/datasets_llama/no_bot_ds\")[\"val\"] # change \n",
    "bot_val = bot_val.add_column(\"output\", [1]*len(bot_val))  \n",
    "no_bot_val = no_bot_val.add_column(\"output\", [0]*len(no_bot_val)) \n",
    "val_dataset = datasets.concatenate_datasets([bot_val, no_bot_val])\n",
    "val_dataset = val_dataset.shuffle(10)\n",
    "val_sentences, val_labels = val_dataset['text'], val_dataset['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbbec8c-90a8-48a6-a77d-3af8eec50d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation sets\n",
    "train_encodings = tokenizer(train_sentences, truncation=True, max_length=512, padding='max_length', return_attention_mask=True)\n",
    "val_encodings = tokenizer(val_sentences, truncation=True, max_length=512, padding='max_length', return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d88dc363-a8d2-4bf7-bd35-8342861aa8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79de59f5-7fb0-46a2-ab0d-b89271eaf8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset = CustomDataset(train_encodings, train_labels)\n",
    "val_dataset = CustomDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e0b203-1efb-4a82-b249-e324570a4a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e91dff-bb0f-4c14-96cf-d804b880977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4940bec9-34cb-4b0d-baf7-06d8ec7d624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float32  #bfloat\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, \n",
    "                                                        quantization_config=bnb_config,\n",
    "                                                        trust_remote_code=True,\n",
    "                                                        num_labels=len(set(train_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed53ed0-04d6-421f-ba58-5da21e391c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7fe9105-09f5-4a0f-8911-f027876f59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e60a232d-944e-4d6b-9c0c-2cb8254c865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4953943-4834-4f19-b076-e20bc4b57abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a1fa0b6-214b-4e4f-8842-8be0b37777c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_linear_names(model):\n",
    "    cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, cls):\n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "    return list(lora_module_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bde4f4-940a-4108-9441-4c55c56af77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = find_all_linear_names(model)\n",
    "modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1cf75-a454-4f8b-ab02-84c370658fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"models/text-based/Llama2/models/\"\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=16, \n",
    "    lora_alpha=64, \n",
    "    target_modules=modules, \n",
    "    lora_dropout=0.4, \n",
    "    bias=\"none\", \n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "\n",
    "   # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(labels, preds, average='binary')\n",
    "    recall = recall_score(labels, preds, average='binary')\n",
    "    f1 = f1_score(labels, preds, average='binary')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    logging_dir=model_directory, \n",
    "    output_dir=model_directory,    # change     \n",
    "    evaluation_strategy='epoch', \n",
    "    load_best_model_at_end = True,\n",
    "    logging_steps = 100, \n",
    "    logging_strategy=\"epoch\",\n",
    "    report_to=\"none\",\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    save_total_limit=2,\n",
    "    save_strategy= \"epoch\",\n",
    "    optim=\"paged_adamw_32bit\", \n",
    "    learning_rate = 2e-5,\n",
    "    fp16 = True, \n",
    "    push_to_hub=False,\n",
    ")\n",
    "print_trainable_parameters(model)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. please re-enable for inference!\n",
    "do_train = True\n",
    "\n",
    "def log_memory_usage():\n",
    "    mem_alloc = torch.cuda.memory_allocated() / 1024**3  # Memory usage in GB\n",
    "    print(f\"Memory Usage: {mem_alloc:.2f} GB\")\n",
    "\n",
    "# Launch training and log metrics\n",
    "print(\"Training...\")\n",
    "\n",
    "\n",
    "if do_train:\n",
    "    train_result = trainer.train()\n",
    "    metrics = train_result.metrics\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "    log_memory_usage()\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11002ee-8904-40eb-bf6b-f020822efbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "print(\"Saving last checkpoint of the model...\")\n",
    "trainer.model.save_pretrained(model_directory, safe_serialization=False)\n",
    "\n",
    "# Free memory for merging weights\n",
    "del model\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05217390-458e-453b-8997-7910ca0bc4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftConfig, PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForSequenceClassification\n",
    "\n",
    "PEFT_MODEL = model_directory #+ \"best-model\"\n",
    "config = PeftConfig.from_pretrained(PEFT_MODEL)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    return_dict=True,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    num_labels=2\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "tokenizer.add_special_tokens({\"pad_token\":\"<pad>\"}) \n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "model = PeftModel.from_pretrained(model, PEFT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86863fdb-44ad-4d35-8e2c-9fdccd2cab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Testdata \n",
    "bot_test = datasets.load_from_disk(\"../../../dataset/datasets_llama/bot_ds\")[\"test\"]\n",
    "no_bot_test = datasets.load_from_disk(\"../../../dataset/datasets_llama/no_bot_ds\")[\"test\"]\n",
    "bot_test = bot_test.add_column(\"output\", [1]*len(bot_test))\n",
    "no_bot_test = no_bot_test.add_column(\"output\", [0]*len(no_bot_test))\n",
    "test_dataset = datasets.concatenate_datasets([bot_test, no_bot_test])\n",
    "test_dataset = test_dataset.shuffle(10)\n",
    "test_sentences, test_labels = test_dataset['text'], test_dataset['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463b54fd-8529-4fa3-8655-5ec3cf42529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "preds = []\n",
    "for sentence in tqdm(test_sentences, desc=\"Evaluation\"):\n",
    "    input = tokenizer(sentence, return_tensors='pt', truncation=True, max_length=512)\n",
    "    pred = model(**input) \n",
    "    preds.append(pred.logits.argmax().item())\n",
    "\n",
    "metric.compute(predictions=preds, references=test_labels, average='binary')[\"f1\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
